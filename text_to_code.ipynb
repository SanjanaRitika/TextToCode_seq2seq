{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2K4bitupMg9yygFkYppJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjanaRitika/TextToCode_seq2seq/blob/main/text_to_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvMy_uRFxKOB"
      },
      "outputs": [],
      "source": [
        "!pip -q install datasets sacrebleu evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, math, re, os, time\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "import sacrebleu\n"
      ],
      "metadata": {
        "id": "wCfY_3OQzr9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "id": "rGTSJ65q0PUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_CANDIDATES = [\n",
        "    \"Nan-Do/code-search-net-python\",\n",
        "    \"code_search_net\",  # official HF name sometimes\n",
        "]\n",
        "\n",
        "ds = None\n",
        "last_err = None\n",
        "for name in DATASET_CANDIDATES:\n",
        "    try:\n",
        "        ds = load_dataset(name)\n",
        "        print(\"Loaded:\", name)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "\n",
        "if ds is None:\n",
        "    raise RuntimeError(f\"Could not load dataset from candidates. Last error: {last_err}\")\n",
        "\n",
        "ds\n"
      ],
      "metadata": {
        "id": "UFjafjWx0bfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)\n",
        "print(ds[\"train\"].column_names)\n"
      ],
      "metadata": {
        "id": "JHpCNbY408oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pair(example):\n",
        "    # common patterns\n",
        "    for doc_key in [\"docstring\", \"func_documentation_string\", \"doc\"]:\n",
        "        if doc_key in example and example[doc_key]:\n",
        "            doc = example[doc_key]\n",
        "            break\n",
        "    else:\n",
        "        doc = \"\"\n",
        "\n",
        "    for code_key in [\"code\", \"func_code_string\", \"function\", \"content\"]:\n",
        "        if code_key in example and example[code_key]:\n",
        "            code = example[code_key]\n",
        "            break\n",
        "    else:\n",
        "        code = \"\"\n",
        "\n",
        "    # some datasets store dicts\n",
        "    if isinstance(doc, dict):\n",
        "        doc = doc.get(\"value\", \"\")\n",
        "    if isinstance(code, dict):\n",
        "        code = code.get(\"value\", \"\")\n",
        "\n",
        "    return doc, code\n",
        "\n",
        "# quick sanity check\n",
        "for i in range(3):\n",
        "    d, c = extract_pair(ds[\"train\"][i])\n",
        "    print(\"DOC:\", d[:120].replace(\"\\n\",\" \"))\n",
        "    print(\"CODE:\", c[:120].replace(\"\\n\",\" \"))\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "XeWEfMjq0_OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_N = 8000\n",
        "VAL_N   = 1000\n",
        "TEST_N  = 1000\n",
        "\n",
        "train_raw = ds[\"train\"].shuffle(seed=42).select(range(TRAIN_N))\n",
        "val_raw   = ds[\"validation\"].shuffle(seed=42).select(range(min(VAL_N, len(ds[\"validation\"]))))\n",
        "test_raw  = ds[\"test\"].shuffle(seed=42).select(range(min(TEST_N, len(ds[\"test\"]))))\n",
        "\n",
        "len(train_raw), len(val_raw), len(test_raw)\n"
      ],
      "metadata": {
        "id": "b2-6q3k_1C7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN_RE = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    return TOKEN_RE.findall(text)\n",
        "\n",
        "PAD, BOS, EOS, UNK = \"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"\n",
        "\n",
        "def build_vocab(pairs, max_size=30000, min_freq=2):\n",
        "    from collections import Counter\n",
        "    cnt = Counter()\n",
        "    for doc, code in pairs:\n",
        "        cnt.update(tokenize(doc))\n",
        "        cnt.update(tokenize(code))\n",
        "    vocab = [PAD, BOS, EOS, UNK]\n",
        "    for tok, f in cnt.most_common():\n",
        "        if f < min_freq:\n",
        "            break\n",
        "        if tok in vocab:\n",
        "            continue\n",
        "        vocab.append(tok)\n",
        "        if len(vocab) >= max_size:\n",
        "            break\n",
        "    stoi = {t:i for i,t in enumerate(vocab)}\n",
        "    itos = {i:t for t,i in stoi.items()}\n",
        "    return vocab, stoi, itos\n",
        "\n",
        "# Build vocab from training only (standard)\n",
        "train_pairs = [extract_pair(ex) for ex in train_raw]\n",
        "vocab, stoi, itos = build_vocab(train_pairs, max_size=30000, min_freq=2)\n",
        "vocab_size = len(vocab)\n",
        "vocab_size\n"
      ],
      "metadata": {
        "id": "ODWq00yp1J4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_N = 8000\n",
        "VAL_N   = 1000\n",
        "TEST_N  = 1000\n",
        "\n",
        "train_raw = ds[\"train\"].shuffle(seed=42).select(range(min(TRAIN_N, len(ds[\"train\"]))))\n",
        "\n",
        "# ---- validation split handling ----\n",
        "if \"validation\" in ds:\n",
        "    val_raw = ds[\"validation\"].shuffle(seed=42).select(\n",
        "        range(min(VAL_N, len(ds[\"validation\"])))\n",
        "    )\n",
        "\n",
        "elif \"valid\" in ds:\n",
        "    val_raw = ds[\"valid\"].shuffle(seed=42).select(\n",
        "        range(min(VAL_N, len(ds[\"valid\"])))\n",
        "    )\n",
        "\n",
        "else:\n",
        "    # create validation from train (10%)\n",
        "    split_idx = int(0.9 * len(train_raw))\n",
        "    val_raw = train_raw.select(range(split_idx, len(train_raw)))\n",
        "    train_raw = train_raw.select(range(split_idx))\n",
        "    print(\"No validation split found — created from train set.\")\n",
        "\n",
        "# ---- test split handling ----\n",
        "if \"test\" in ds:\n",
        "    test_raw = ds[\"test\"].shuffle(seed=42).select(\n",
        "        range(min(TEST_N, len(ds[\"test\"])))\n",
        "    )\n",
        "else:\n",
        "    # fallback if test missing\n",
        "    test_raw = val_raw\n",
        "    print(\"No test split found — using validation as test.\")\n"
      ],
      "metadata": {
        "id": "Gf6curtr1QwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeGenDataset(Dataset):\n",
        "    def __init__(self, enc_list: List[EncodedExample]):\n",
        "        self.data = enc_list\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.data[idx]\n",
        "        return (\n",
        "            torch.tensor(ex.src_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_in_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_out_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.src_len, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_len, dtype=torch.long),\n",
        "        )\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(CodeGenDataset(train_enc), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(CodeGenDataset(val_enc), batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(CodeGenDataset(test_enc), batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "E1rn9uaf169P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)\n",
        "print(ds.keys())\n"
      ],
      "metadata": {
        "id": "V5bNmKsC2Wbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_N = 8000\n",
        "VAL_N   = 1000\n",
        "TEST_N  = 1000\n",
        "\n",
        "train_raw = ds[\"train\"].shuffle(seed=42).select(range(min(TRAIN_N, len(ds[\"train\"]))))\n",
        "\n",
        "# ---- validation split handling ----\n",
        "if \"validation\" in ds:\n",
        "    val_raw = ds[\"validation\"].shuffle(seed=42).select(\n",
        "        range(min(VAL_N, len(ds[\"validation\"])))\n",
        "    )\n",
        "\n",
        "elif \"valid\" in ds:\n",
        "    val_raw = ds[\"valid\"].shuffle(seed=42).select(\n",
        "        range(min(VAL_N, len(ds[\"valid\"])))\n",
        "    )\n",
        "\n",
        "else:\n",
        "    # create validation from train (10%)\n",
        "    split_idx = int(0.9 * len(train_raw))\n",
        "    val_raw = train_raw.select(range(split_idx, len(train_raw)))\n",
        "    train_raw = train_raw.select(range(split_idx))\n",
        "    print(\"No validation split found — created from train set.\")\n",
        "\n",
        "# ---- test split handling ----\n",
        "if \"test\" in ds:\n",
        "    test_raw = ds[\"test\"].shuffle(seed=42).select(\n",
        "        range(min(TEST_N, len(ds[\"test\"])))\n",
        "    )\n",
        "else:\n",
        "    # fallback if test missing\n",
        "    test_raw = val_raw\n",
        "    print(\"No test split found — using validation as test.\")\n"
      ],
      "metadata": {
        "id": "1GZSdIhO2bVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN_RE = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    return TOKEN_RE.findall(text)\n",
        "\n",
        "PAD, BOS, EOS, UNK = \"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"\n",
        "\n",
        "def build_vocab(pairs, max_size=30000, min_freq=2):\n",
        "    from collections import Counter\n",
        "    cnt = Counter()\n",
        "    for doc, code in pairs:\n",
        "        cnt.update(tokenize(doc))\n",
        "        cnt.update(tokenize(code))\n",
        "    vocab = [PAD, BOS, EOS, UNK]\n",
        "    for tok, f in cnt.most_common():\n",
        "        if f < min_freq:\n",
        "            break\n",
        "        if tok in vocab:\n",
        "            continue\n",
        "        vocab.append(tok)\n",
        "        if len(vocab) >= max_size:\n",
        "            break\n",
        "    stoi = {t:i for i,t in enumerate(vocab)}\n",
        "    itos = {i:t for t,i in stoi.items()}\n",
        "    return vocab, stoi, itos\n",
        "\n",
        "# Build vocab from training only (standard)\n",
        "train_pairs = [extract_pair(ex) for ex in train_raw]\n",
        "vocab, stoi, itos = build_vocab(train_pairs, max_size=30000, min_freq=2)\n",
        "vocab_size = len(vocab)\n",
        "vocab_size\n"
      ],
      "metadata": {
        "id": "3hDAjR8B2wjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SRC = 50\n",
        "MAX_TGT = 80\n",
        "\n",
        "def encode(tokens: List[str], max_len: int):\n",
        "    tokens = tokens[:max_len]\n",
        "    ids = [stoi.get(t, stoi[UNK]) for t in tokens]\n",
        "    return ids\n",
        "\n",
        "def add_bos_eos(ids: List[int], max_len: int):\n",
        "    ids = [stoi[BOS]] + ids + [stoi[EOS]]\n",
        "    # keep within max_len+2 budget\n",
        "    ids = ids[:max_len+2]\n",
        "    return ids\n",
        "\n",
        "def pad(ids: List[int], max_total_len: int):\n",
        "    if len(ids) < max_total_len:\n",
        "        ids = ids + [stoi[PAD]]*(max_total_len - len(ids))\n",
        "    return ids\n",
        "\n",
        "@dataclass\n",
        "class EncodedExample:\n",
        "    src_ids: List[int]\n",
        "    tgt_in_ids: List[int]   # decoder input (starts with BOS)\n",
        "    tgt_out_ids: List[int]  # labels (shifted, ends with EOS)\n",
        "    src_len: int\n",
        "    tgt_len: int\n",
        "    raw_doc: str\n",
        "    raw_code: str\n",
        "\n",
        "def preprocess_pair(doc, code):\n",
        "    src_tok = tokenize(doc)\n",
        "    tgt_tok = tokenize(code)\n",
        "\n",
        "    src_ids = add_bos_eos(encode(src_tok, MAX_SRC), MAX_SRC)\n",
        "    tgt_ids = add_bos_eos(encode(tgt_tok, MAX_TGT), MAX_TGT)\n",
        "\n",
        "    # decoder: input is all but last, output is all but first\n",
        "    tgt_in  = tgt_ids[:-1]\n",
        "    tgt_out = tgt_ids[1:]\n",
        "\n",
        "    src_len = min(len(src_ids), MAX_SRC+2)\n",
        "    tgt_len = min(len(tgt_in), MAX_TGT+1)\n",
        "\n",
        "    src_ids = pad(src_ids, MAX_SRC+2)\n",
        "    tgt_in  = pad(tgt_in,  MAX_TGT+1)\n",
        "    tgt_out = pad(tgt_out, MAX_TGT+1)\n",
        "\n",
        "    return EncodedExample(src_ids, tgt_in, tgt_out, src_len, tgt_len, doc, code)\n",
        "\n",
        "train_enc = [preprocess_pair(*extract_pair(ex)) for ex in train_raw]\n",
        "val_enc   = [preprocess_pair(*extract_pair(ex)) for ex in val_raw]\n",
        "test_enc  = [preprocess_pair(*extract_pair(ex)) for ex in test_raw]\n",
        "\n",
        "len(train_enc), len(val_enc), len(test_enc)\n"
      ],
      "metadata": {
        "id": "gmwW31VL22h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeGenDataset(Dataset):\n",
        "    def __init__(self, enc_list: List[EncodedExample]):\n",
        "        self.data = enc_list\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.data[idx]\n",
        "        return (\n",
        "            torch.tensor(ex.src_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_in_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_out_ids, dtype=torch.long),\n",
        "            torch.tensor(ex.src_len, dtype=torch.long),\n",
        "            torch.tensor(ex.tgt_len, dtype=torch.long),\n",
        "        )\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(CodeGenDataset(train_enc), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(CodeGenDataset(val_enc), batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(CodeGenDataset(test_enc), batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "aBgQOjCC2_V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_accuracy(logits, targets, pad_idx):\n",
        "    # logits: [B, T, V], targets: [B, T]\n",
        "    preds = logits.argmax(-1)\n",
        "    mask = targets != pad_idx\n",
        "    correct = (preds == targets) & mask\n",
        "    return correct.sum().item() / (mask.sum().item() + 1e-9)\n",
        "\n",
        "def ids_to_text(ids: List[int]):\n",
        "    toks = []\n",
        "    for i in ids:\n",
        "        if i == stoi[EOS]:\n",
        "            break\n",
        "        if i in (stoi[PAD], stoi[BOS]):\n",
        "            continue\n",
        "        toks.append(itos.get(int(i), UNK))\n",
        "    # join with space; for code it won’t be perfect but works for BLEU + inspection\n",
        "    return \" \".join(toks)\n"
      ],
      "metadata": {
        "id": "2As-TIhd3EHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.rnn = nn.RNN(emb_dim, hid_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        # src: [B, S]\n",
        "        emb = self.emb(src)\n",
        "        out, h = self.rnn(emb)  # out: [B,S,H], h: [1,B,H]\n",
        "        return out, h\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.rnn = nn.RNN(emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc  = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, tgt_in, h):\n",
        "        emb = self.emb(tgt_in)          # [B,T,E]\n",
        "        out, h = self.rnn(emb, h)       # [B,T,H]\n",
        "        logits = self.fc(out)           # [B,T,V]\n",
        "        return logits, h\n",
        "\n",
        "class Seq2SeqNoAttn(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_len, tgt_in):\n",
        "        _, h = self.encoder(src, src_len)\n",
        "        logits, _ = self.decoder(tgt_in, h)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "TmcNxyow3IZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        emb = self.emb(src)\n",
        "        out, (h, c) = self.lstm(emb)  # h,c: [1,B,H]\n",
        "        return out, (h, c)\n",
        "\n",
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc  = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, tgt_in, hc):\n",
        "        emb = self.emb(tgt_in)\n",
        "        out, hc = self.lstm(emb, hc)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hc\n",
        "\n",
        "class Seq2SeqLSTMNoAttn(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_len, tgt_in):\n",
        "        _, hc = self.encoder(src, src_len)\n",
        "        logits, _ = self.decoder(tgt_in, hc)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "lckyyDlE3MCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_dim, dec_dim, attn_dim):\n",
        "        super().__init__()\n",
        "        self.W_enc = nn.Linear(enc_dim, attn_dim, bias=False)\n",
        "        self.W_dec = nn.Linear(dec_dim, attn_dim, bias=False)\n",
        "        self.v     = nn.Linear(attn_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, enc_out, dec_h, src_mask):\n",
        "        # enc_out: [B,S,enc_dim], dec_h: [B,dec_dim], mask: [B,S] (1 for valid)\n",
        "        # score = v^T tanh(W_enc(enc_out) + W_dec(dec_h))\n",
        "        e = self.W_enc(enc_out) + self.W_dec(dec_h).unsqueeze(1)  # [B,S,A]\n",
        "        scores = self.v(torch.tanh(e)).squeeze(-1)                # [B,S]\n",
        "\n",
        "        scores = scores.masked_fill(src_mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)                      # [B,S]\n",
        "        ctx = torch.bmm(attn.unsqueeze(1), enc_out).squeeze(1)    # [B,enc_dim]\n",
        "        return ctx, attn\n",
        "\n",
        "class EncoderBiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        emb = self.emb(src)\n",
        "        out, (h, c) = self.lstm(emb)  # out: [B,S,2H], h,c: [2,B,H]\n",
        "        return out, (h, c)\n",
        "\n",
        "class DecoderAttnLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, enc_out_dim, hid_dim, attn_dim=256):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=stoi[PAD])\n",
        "        self.attn = BahdanauAttention(enc_out_dim, hid_dim, attn_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim + enc_out_dim, hid_dim, batch_first=True)\n",
        "        self.fc   = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, tgt_in, enc_out, hc, src_mask):\n",
        "        # teacher forcing full sequence\n",
        "        B, T = tgt_in.shape\n",
        "        emb = self.emb(tgt_in)  # [B,T,E]\n",
        "        h, c = hc\n",
        "        h = h.squeeze(0)        # [B,H]\n",
        "        c = c.squeeze(0)        # [B,H]\n",
        "\n",
        "        all_logits = []\n",
        "        all_attn = []\n",
        "\n",
        "        for t in range(T):\n",
        "            ctx, attn_w = self.attn(enc_out, h, src_mask)   # ctx: [B,enc_dim]\n",
        "            x = torch.cat([emb[:, t, :], ctx], dim=-1).unsqueeze(1)  # [B,1,E+enc]\n",
        "            out, (h1, c1) = self.lstm(x, (h.unsqueeze(0), c.unsqueeze(0)))\n",
        "            h = h1.squeeze(0); c = c1.squeeze(0)\n",
        "            logits = self.fc(out.squeeze(1))                # [B,V]\n",
        "            all_logits.append(logits.unsqueeze(1))\n",
        "            all_attn.append(attn_w.unsqueeze(1))\n",
        "\n",
        "        logits = torch.cat(all_logits, dim=1)  # [B,T,V]\n",
        "        attn   = torch.cat(all_attn, dim=1)    # [B,T,S]\n",
        "        return logits, attn\n",
        "\n",
        "class Seq2SeqAttn(nn.Module):\n",
        "    def __init__(self, encoder_bi, decoder_attn, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder_bi\n",
        "        self.decoder = decoder_attn\n",
        "        # bridge biLSTM states -> decoder initial\n",
        "        self.bridge_h = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "        self.bridge_c = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "\n",
        "    def forward(self, src, src_len, tgt_in):\n",
        "        enc_out, (h, c) = self.encoder(src, src_len)  # h,c: [2,B,H]\n",
        "        # concat directions\n",
        "        h_cat = torch.cat([h[0], h[1]], dim=-1)  # [B,2H]\n",
        "        c_cat = torch.cat([c[0], c[1]], dim=-1)\n",
        "        h0 = torch.tanh(self.bridge_h(h_cat)).unsqueeze(0)  # [1,B,H]\n",
        "        c0 = torch.tanh(self.bridge_c(c_cat)).unsqueeze(0)\n",
        "\n",
        "        src_mask = (src != stoi[PAD]).long()  # [B,S]\n",
        "        logits, attn = self.decoder(tgt_in, enc_out, (h0, c0), src_mask)\n",
        "        return logits, attn\n"
      ],
      "metadata": {
        "id": "NC4mnKlU3OeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, loader, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train() if is_train else model.eval()\n",
        "\n",
        "    ce = nn.CrossEntropyLoss(ignore_index=stoi[PAD])\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for src, tgt_in, tgt_out, src_len, tgt_len in loader:\n",
        "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            out = model(src, src_len, tgt_in)\n",
        "            if isinstance(out, tuple):\n",
        "                logits = out[0]\n",
        "            else:\n",
        "                logits = out\n",
        "\n",
        "            loss = ce(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "            acc  = token_accuracy(logits, tgt_out, stoi[PAD])\n",
        "\n",
        "            if is_train:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc  += acc\n",
        "        n_batches += 1\n",
        "\n",
        "    return total_loss / n_batches, total_acc / n_batches\n"
      ],
      "metadata": {
        "id": "ZCiAohf63STV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=8, lr=1e-3, ckpt_path=\"model.pt\"):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr_loss, tr_acc = run_epoch(model, train_loader, optimizer)\n",
        "        va_loss, va_acc = run_epoch(model, val_loader, None)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"val_loss\"].append(va_loss)\n",
        "        history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"val_acc\"].append(va_acc)\n",
        "\n",
        "        print(f\"Epoch {ep}: train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
        "\n",
        "        if va_loss < best_val:\n",
        "            best_val = va_loss\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            print(\"  saved:\", ckpt_path)\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "Ldzv--W03U1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMB_DIM = 256\n",
        "HID_DIM = 256\n",
        "\n",
        "# Model 1\n",
        "m1 = Seq2SeqNoAttn(\n",
        "    EncoderRNN(vocab_size, EMB_DIM, HID_DIM),\n",
        "    DecoderRNN(vocab_size, EMB_DIM, HID_DIM)\n",
        ")\n",
        "\n",
        "# Model 2\n",
        "m2 = Seq2SeqLSTMNoAttn(\n",
        "    EncoderLSTM(vocab_size, EMB_DIM, HID_DIM),\n",
        "    DecoderLSTM(vocab_size, EMB_DIM, HID_DIM)\n",
        ")\n",
        "\n",
        "# Model 3\n",
        "enc3 = EncoderBiLSTM(vocab_size, EMB_DIM, HID_DIM)\n",
        "# encoder out dim = 2*HID_DIM\n",
        "dec3 = DecoderAttnLSTM(vocab_size, EMB_DIM, enc_out_dim=2*HID_DIM, hid_dim=HID_DIM, attn_dim=256)\n",
        "m3 = Seq2SeqAttn(enc3, dec3, enc_hid_dim=HID_DIM, dec_hid_dim=HID_DIM)\n",
        "\n",
        "hist1 = train_model(m1, epochs=8, ckpt_path=\"m1_rnn.pt\")\n",
        "hist2 = train_model(m2, epochs=8, ckpt_path=\"m2_lstm.pt\")\n",
        "hist3 = train_model(m3, epochs=8, ckpt_path=\"m3_attn.pt\")\n"
      ],
      "metadata": {
        "id": "d4CY0_6E5Yh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(hist, title):\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(hist1, \"Model 1: RNN Seq2Seq\")\n",
        "plot_history(hist2, \"Model 2: LSTM Seq2Seq\")\n",
        "plot_history(hist3, \"Model 3: BiLSTM + Attention\")\n"
      ],
      "metadata": {
        "id": "SRZ86eAPAi8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def greedy_decode_noattn(model, src_ids, max_len=80):\n",
        "    model.eval()\n",
        "    src = torch.tensor([src_ids], dtype=torch.long).to(device)\n",
        "    src_len = torch.tensor([min(len(src_ids), MAX_SRC+2)], dtype=torch.long)\n",
        "\n",
        "    # encode\n",
        "    enc = model.encoder\n",
        "    dec = model.decoder\n",
        "\n",
        "    if isinstance(enc, EncoderRNN):\n",
        "        _, h = enc(src, src_len)\n",
        "        hc = h\n",
        "        use_lstm = False\n",
        "    else:\n",
        "        _, hc = enc(src, src_len)\n",
        "        use_lstm = True\n",
        "\n",
        "    y = [stoi[BOS]]\n",
        "    for _ in range(max_len+1):\n",
        "        tgt_in = torch.tensor([y], dtype=torch.long).to(device)\n",
        "        if use_lstm:\n",
        "            logits, hc = dec(tgt_in[:, -1:], hc)  # step\n",
        "        else:\n",
        "            logits, hc = dec(tgt_in[:, -1:], hc)\n",
        "        next_id = int(logits[0,0].argmax(-1))\n",
        "        y.append(next_id)\n",
        "        if next_id == stoi[EOS]:\n",
        "            break\n",
        "    return y\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_decode_attn(model, src_ids, max_len=80):\n",
        "    model.eval()\n",
        "    src = torch.tensor([src_ids], dtype=torch.long).to(device)\n",
        "    src_len = torch.tensor([min(len(src_ids), MAX_SRC+2)], dtype=torch.long)\n",
        "\n",
        "    enc_out, (h, c) = model.encoder(src, src_len)\n",
        "    h_cat = torch.cat([h[0], h[1]], dim=-1)\n",
        "    c_cat = torch.cat([c[0], c[1]], dim=-1)\n",
        "    h0 = torch.tanh(model.bridge_h(h_cat)).unsqueeze(0)\n",
        "    c0 = torch.tanh(model.bridge_c(c_cat)).unsqueeze(0)\n",
        "\n",
        "    src_mask = (src != stoi[PAD]).long()\n",
        "    h = h0; c = c0\n",
        "\n",
        "    y = [stoi[BOS]]\n",
        "    attn_maps = []\n",
        "\n",
        "    for _ in range(max_len+1):\n",
        "        tgt_step = torch.tensor([[y[-1]]], dtype=torch.long).to(device)\n",
        "        emb = model.decoder.emb(tgt_step)  # [1,1,E]\n",
        "\n",
        "        h_flat = h.squeeze(0)\n",
        "        ctx, attn_w = model.decoder.attn(enc_out, h_flat, src_mask)\n",
        "        x = torch.cat([emb.squeeze(1), ctx], dim=-1).unsqueeze(1)  # [1,1,E+enc]\n",
        "\n",
        "        out, (h, c) = model.decoder.lstm(x, (h, c))\n",
        "        logits = model.decoder.fc(out.squeeze(1))  # [1,V]\n",
        "        next_id = int(logits[0].argmax(-1))\n",
        "        y.append(next_id)\n",
        "        attn_maps.append(attn_w.squeeze(0).cpu().numpy())  # [S]\n",
        "        if next_id == stoi[EOS]:\n",
        "            break\n",
        "\n",
        "    return y, np.array(attn_maps)  # [T,S]\n"
      ],
      "metadata": {
        "id": "pbvUTsOPEYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_generation(model, is_attn=False, n_samples=500):\n",
        "    refs = []\n",
        "    hyps = []\n",
        "    exact = 0\n",
        "\n",
        "    # take subset for speed\n",
        "    idxs = list(range(len(test_enc)))\n",
        "    random.shuffle(idxs)\n",
        "    idxs = idxs[:n_samples]\n",
        "\n",
        "    for i in idxs:\n",
        "        ex = test_enc[i]\n",
        "        src_ids = ex.src_ids\n",
        "        ref_text = ex.raw_code.strip()\n",
        "\n",
        "        if is_attn:\n",
        "            hyp_ids, _ = greedy_decode_attn(model, src_ids, max_len=MAX_TGT)\n",
        "        else:\n",
        "            hyp_ids = greedy_decode_noattn(model, src_ids, max_len=MAX_TGT)\n",
        "\n",
        "        hyp_text = ids_to_text(hyp_ids)\n",
        "\n",
        "        refs.append([ref_text])\n",
        "        hyps.append(hyp_text)\n",
        "\n",
        "        if hyp_text.strip() == ref_text.strip():\n",
        "            exact += 1\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(hyps, list(zip(*refs))[0]).score\n",
        "    exact_match = exact / len(hyps)\n",
        "    return bleu, exact_match\n",
        "\n",
        "# load best checkpoints before eval\n",
        "m1.load_state_dict(torch.load(\"m1_rnn.pt\", map_location=device))\n",
        "m2.load_state_dict(torch.load(\"m2_lstm.pt\", map_location=device))\n",
        "m3.load_state_dict(torch.load(\"m3_attn.pt\", map_location=device))\n",
        "\n",
        "bleu1, em1 = evaluate_generation(m1, is_attn=False, n_samples=500)\n",
        "bleu2, em2 = evaluate_generation(m2, is_attn=False, n_samples=500)\n",
        "bleu3, em3 = evaluate_generation(m3, is_attn=True,  n_samples=500)\n",
        "\n",
        "print(\"RNN     BLEU:\", bleu1, \"ExactMatch:\", em1)\n",
        "print(\"LSTM    BLEU:\", bleu2, \"ExactMatch:\", em2)\n",
        "print(\"Attn    BLEU:\", bleu3, \"ExactMatch:\", em3)\n"
      ],
      "metadata": {
        "id": "4KJ3wE3YEblB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_attention(doc, hyp, attn, src_tokens):\n",
        "    # hyp tokens: use tokenizer on generated text for axis labeling\n",
        "    tgt_tokens = tokenize(hyp)[:attn.shape[0]]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(attn[:len(tgt_tokens), :len(src_tokens)], aspect=\"auto\")\n",
        "    plt.yticks(range(len(tgt_tokens)), tgt_tokens)\n",
        "    plt.xticks(range(len(src_tokens)), src_tokens, rotation=60, ha=\"right\")\n",
        "    plt.xlabel(\"Docstring tokens\")\n",
        "    plt.ylabel(\"Generated code tokens\")\n",
        "    plt.title(\"Attention alignment\")\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# pick 3 test examples\n",
        "for i in [0, 1, 2]:\n",
        "    ex = test_enc[i]\n",
        "    src_tokens = [BOS] + tokenize(ex.raw_doc)[:MAX_SRC] + [EOS]\n",
        "\n",
        "    hyp_ids, attn = greedy_decode_attn(m3, ex.src_ids, max_len=MAX_TGT)\n",
        "    hyp_text = ids_to_text(hyp_ids)\n",
        "\n",
        "    print(\"DOC:\", ex.raw_doc[:200].replace(\"\\n\",\" \"))\n",
        "    print(\"HYP:\", hyp_text[:200].replace(\"\\n\",\" \"))\n",
        "    print(\"REF:\", ex.raw_code[:200].replace(\"\\n\",\" \"))\n",
        "    plot_attention(ex.raw_doc, hyp_text, attn, src_tokens)\n"
      ],
      "metadata": {
        "id": "5AJXTQ1NFnQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}